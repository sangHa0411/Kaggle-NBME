{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:00.477482Z","iopub.execute_input":"2022-03-09T18:04:00.477896Z","iopub.status.idle":"2022-03-09T18:04:01.628759Z","shell.execute_reply.started":"2022-03-09T18:04:00.477851Z","shell.execute_reply":"2022-03-09T18:04:01.627194Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"## Library","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport torch\nimport torch.nn as n\nimport torch.nn.functional as F\nimport argparse\nimport importlib\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (AutoTokenizer, \n    AutoConfig, \n    AutoModelForTokenClassification, \n    Trainer, \n    DataCollatorWithPadding\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:01.632178Z","iopub.execute_input":"2022-03-09T18:04:01.633000Z","iopub.status.idle":"2022-03-09T18:04:01.651032Z","shell.execute_reply.started":"2022-03-09T18:04:01.632944Z","shell.execute_reply":"2022-03-09T18:04:01.649796Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## PLM","metadata":{}},{"cell_type":"code","source":"TOKENIZER = '/kaggle/input/roberta-large/tokenizer'\nPLM_BASE = '/kaggle/input/roberta-large/'\nMAX_LENGTH = 512\nBATCH_SIZE = 4\nK_FOLD = 5","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:01.653549Z","iopub.execute_input":"2022-03-09T18:04:01.654530Z","iopub.status.idle":"2022-03-09T18:04:01.667550Z","shell.execute_reply.started":"2022-03-09T18:04:01.654482Z","shell.execute_reply":"2022-03-09T18:04:01.666284Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"## Load Datasets","metadata":{}},{"cell_type":"code","source":"dir_path = '/kaggle/input/nbme-score-clinical-patient-notes/'","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:01.670290Z","iopub.execute_input":"2022-03-09T18:04:01.670996Z","iopub.status.idle":"2022-03-09T18:04:01.680141Z","shell.execute_reply.started":"2022-03-09T18:04:01.670951Z","shell.execute_reply":"2022-03-09T18:04:01.678493Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(dir_path, 'test.csv'))\npatients_df = pd.read_csv(os.path.join(dir_path, 'patient_notes.csv'))\nfeatures_df = pd.read_csv(os.path.join(dir_path, 'features.csv'))\n\ntest_df = test_df.merge(features_df, on=['feature_num', 'case_num'], how='left')\ntest_df = test_df.merge(patients_df, on=['pn_num', 'case_num'], how='left')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:01.686455Z","iopub.execute_input":"2022-03-09T18:04:01.687013Z","iopub.status.idle":"2022-03-09T18:04:02.106842Z","shell.execute_reply.started":"2022-03-09T18:04:01.686967Z","shell.execute_reply":"2022-03-09T18:04:02.105589Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"test_size = len(test_df)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.109406Z","iopub.execute_input":"2022-03-09T18:04:02.110058Z","iopub.status.idle":"2022-03-09T18:04:02.129681Z","shell.execute_reply.started":"2022-03-09T18:04:02.110012Z","shell.execute_reply":"2022-03-09T18:04:02.128471Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing Datasets","metadata":{}},{"cell_type":"code","source":"feature_text = list(test_df['feature_text'])\npn_history = list(test_df['pn_history'])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.131882Z","iopub.execute_input":"2022-03-09T18:04:02.132319Z","iopub.status.idle":"2022-03-09T18:04:02.138704Z","shell.execute_reply.started":"2022-03-09T18:04:02.132277Z","shell.execute_reply":"2022-03-09T18:04:02.137372Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.140938Z","iopub.execute_input":"2022-03-09T18:04:02.142047Z","iopub.status.idle":"2022-03-09T18:04:02.258992Z","shell.execute_reply.started":"2022-03-09T18:04:02.141964Z","shell.execute_reply":"2022-03-09T18:04:02.257777Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"inputs = [pn_history[i] + tokenizer.sep_token + feature_text[i] for i in range(len(test_df))]\nencoded = tokenizer(inputs,\n    return_offsets_mapping=True,\n    return_token_type_ids=False,\n    truncation=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.260828Z","iopub.execute_input":"2022-03-09T18:04:02.261165Z","iopub.status.idle":"2022-03-09T18:04:02.287228Z","shell.execute_reply.started":"2022-03-09T18:04:02.261117Z","shell.execute_reply":"2022-03-09T18:04:02.286093Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"input_ids = encoded['input_ids']\nattention_mask = encoded['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.289409Z","iopub.execute_input":"2022-03-09T18:04:02.290317Z","iopub.status.idle":"2022-03-09T18:04:02.296171Z","shell.execute_reply.started":"2022-03-09T18:04:02.290270Z","shell.execute_reply":"2022-03-09T18:04:02.294737Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"## Datasets","metadata":{}},{"cell_type":"code","source":"class TestDataset(Dataset) :\n    def __init__(self, input_ids, attention_mask) :\n        super(TestDataset , self).__init__()\n        self.input_ids = input_ids\n        self.attention_mask = attention_mask\n        \n    def __len__(self) :\n        return len(self.input_ids)\n\n    def __getitem__(self , idx) :\n        return {'input_ids' : self.input_ids[idx], 'attention_mask' : self.attention_mask[idx]}","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.298366Z","iopub.execute_input":"2022-03-09T18:04:02.299248Z","iopub.status.idle":"2022-03-09T18:04:02.309983Z","shell.execute_reply.started":"2022-03-09T18:04:02.299200Z","shell.execute_reply":"2022-03-09T18:04:02.308761Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"dataset = TestDataset(input_ids, attention_mask)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.311768Z","iopub.execute_input":"2022-03-09T18:04:02.312528Z","iopub.status.idle":"2022-03-09T18:04:02.320727Z","shell.execute_reply.started":"2022-03-09T18:04:02.312477Z","shell.execute_reply":"2022-03-09T18:04:02.319543Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## Collator","metadata":{}},{"cell_type":"code","source":"collator = DataCollatorWithPadding(tokenizer=tokenizer, max_length=MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.322293Z","iopub.execute_input":"2022-03-09T18:04:02.323520Z","iopub.status.idle":"2022-03-09T18:04:02.330654Z","shell.execute_reply.started":"2022-03-09T18:04:02.323336Z","shell.execute_reply":"2022-03-09T18:04:02.329416Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"## Device","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.336173Z","iopub.execute_input":"2022-03-09T18:04:02.336808Z","iopub.status.idle":"2022-03-09T18:04:02.343743Z","shell.execute_reply.started":"2022-03-09T18:04:02.336757Z","shell.execute_reply":"2022-03-09T18:04:02.342267Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{}},{"cell_type":"code","source":"data_loader = DataLoader(dataset, batch_size=4, shuffle=False, collate_fn=collator)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.346059Z","iopub.execute_input":"2022-03-09T18:04:02.346707Z","iopub.status.idle":"2022-03-09T18:04:02.372820Z","shell.execute_reply.started":"2022-03-09T18:04:02.346638Z","shell.execute_reply":"2022-03-09T18:04:02.371478Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"offset_mapping = encoded.pop('offset_mapping')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.375924Z","iopub.execute_input":"2022-03-09T18:04:02.376407Z","iopub.status.idle":"2022-03-09T18:04:02.386528Z","shell.execute_reply.started":"2022-03-09T18:04:02.376361Z","shell.execute_reply":"2022-03-09T18:04:02.385353Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"predictions = []\n\nfor i in tqdm(range(K_FOLD)) :\n    plm = 'fold-' + str(i+1)\n    model_path = os.path.join(PLM_BASE, plm)\n    \n    config = AutoConfig.from_pretrained(model_path)\n    model = AutoModelForTokenClassification.from_pretrained(model_path, config=config).to(device)\n    model.eval()\n    \n    probs_list = []\n\n    for data in tqdm(data_loader) :\n        data = {k:v.to(device) for k,v in data.items()}\n        results = model(**data)\n\n        logits = results.logits\n        probs = F.softmax(logits, dim=-1).detach().cpu().numpy()\n        probs = [prob for prob in probs]\n        \n        probs_list.extend(probs)\n        \n    predictions.append(probs_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:02.388769Z","iopub.execute_input":"2022-03-09T18:04:02.389158Z","iopub.status.idle":"2022-03-09T18:04:55.011153Z","shell.execute_reply.started":"2022-03-09T18:04:02.389113Z","shell.execute_reply":"2022-03-09T18:04:55.009975Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"results = []\n\nfor i in tqdm(range(test_size)) :\n    pred_list = [predictions[j][i] for j in range(K_FOLD)]\n    preds = np.mean(pred_list, axis=0)\n    pred_ids = np.argmax(preds, axis=-1)\n    results.append(pred_ids)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:55.014572Z","iopub.execute_input":"2022-03-09T18:04:55.014909Z","iopub.status.idle":"2022-03-09T18:04:55.065913Z","shell.execute_reply.started":"2022-03-09T18:04:55.014863Z","shell.execute_reply":"2022-03-09T18:04:55.064913Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"## Postprocessing Datasets","metadata":{}},{"cell_type":"code","source":"def postprocess(pos_list) :\n    idx = 0\n    start = 0\n\n    results = []\n    while(idx < len(pos_list)) :\n        if idx + 1 == len(pos_list) :\n            prev_start, prev_end = pos_list[start]\n            cur_start, cur_end = pos_list[idx]\n\n            results.append([prev_start, cur_end])\n            idx += 1\n        else :\n            prev_start, prev_end = pos_list[idx]\n            cur_start, cur_end = pos_list[idx+1]\n\n            if cur_start == prev_end + 1 or cur_start == prev_end :\n                idx += 1\n            else :\n                span_start = pos_list[start][0]\n                span_end = pos_list[idx][1]\n\n                results.append([span_start, span_end])\n                start = idx+1\n                idx = start\n    \n    results = [[str(span[0]), str(span[1])] for span in results]\n    span_list = [' '.join(span) for span in results]\n    return ';'.join(span_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:55.067990Z","iopub.execute_input":"2022-03-09T18:04:55.068719Z","iopub.status.idle":"2022-03-09T18:04:55.082273Z","shell.execute_reply.started":"2022-03-09T18:04:55.068664Z","shell.execute_reply":"2022-03-09T18:04:55.081253Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"locations = []\n\nfor i, pred in enumerate(results) :\n    offset = offset_mapping[i]\n    input_ids = encoded['input_ids'][i]\n    \n    token_start_index = 1\n    token_end_index = input_ids.index(tokenizer.sep_token_id)\n    \n    span_list = []\n    for j in range(token_start_index, token_end_index) :\n        if pred[j] == 1 :\n            span_list.append(offset[j])\n            \n    span = '' if len(span_list) == 0 else postprocess(span_list)\n    locations.append(span)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:55.084631Z","iopub.execute_input":"2022-03-09T18:04:55.085242Z","iopub.status.idle":"2022-03-09T18:04:55.097331Z","shell.execute_reply.started":"2022-03-09T18:04:55.085185Z","shell.execute_reply":"2022-03-09T18:04:55.096018Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"test_df['location'] = locations\ntest_df = test_df.drop(columns = ['case_num', 'pn_num', 'feature_num', 'feature_text', 'pn_history'])\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:55.099474Z","iopub.execute_input":"2022-03-09T18:04:55.100176Z","iopub.status.idle":"2022-03-09T18:04:55.122413Z","shell.execute_reply.started":"2022-03-09T18:04:55.100131Z","shell.execute_reply":"2022-03-09T18:04:55.121501Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:04:55.124114Z","iopub.execute_input":"2022-03-09T18:04:55.124486Z","iopub.status.idle":"2022-03-09T18:04:55.132962Z","shell.execute_reply.started":"2022-03-09T18:04:55.124423Z","shell.execute_reply":"2022-03-09T18:04:55.131658Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}